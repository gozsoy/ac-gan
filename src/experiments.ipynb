{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roadmap:\n",
    "# 1-implement dcgan in tf and observe generated examples\n",
    "# 2-investigate tf dcgan implementation\n",
    "# 3-implement dcgan in torch and observed generated examples\n",
    "# 4-investigate torch dcgan implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = np.expand_dims(x_train,axis=3)\n",
    "x_train = tf.cast(x_train,dtype=tf.float32)\n",
    "\n",
    "# [0,255] -> [0,1] -> [-1,1]\n",
    "x_train = (x_train/255.) * 2. - 1.\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_ds = train_ds.shuffle(1000).batch(64)\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's say batch is 2\n",
    "batch_size = 2\n",
    "latent_code = tf.random.normal(shape=(batch_size,100))\n",
    "\n",
    "# GENERATOR\n",
    "# use batchnorm and dropout on G\n",
    "inputs = tf.keras.Input(shape=(100,))\n",
    "x = tf.keras.layers.Dense(units=(4*4*256),activation='relu')(inputs)\n",
    "x = tf.reshape(x,[-1,4,4,256])\n",
    "x = tf.keras.layers.Conv2DTranspose(filters=128,kernel_size=5,strides=2,activation='relu',padding='same')(x)\n",
    "x = tf.keras.layers.Conv2DTranspose(filters=64,kernel_size=7,strides=1,activation='relu',padding='valid')(x)\n",
    "outputs = tf.keras.layers.Conv2DTranspose(filters=1,kernel_size=5,strides=2,activation='tanh',padding='same')(x)\n",
    "\n",
    "Generator = tf.keras.Model(inputs=inputs, outputs=[outputs])\n",
    "\n",
    "# DISCRIMINATOR\n",
    "# use batchnorm on D\n",
    "inputs = tf.keras.Input(shape=(28,28,1))\n",
    "x = tf.keras.layers.Conv2D(filters=64,kernel_size=5,strides=2)(inputs)\n",
    "x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "x = tf.keras.layers.Conv2D(filters=128,kernel_size=5,strides=2)(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "outputs = tf.keras.layers.Dense(units=1)(x)\n",
    "\n",
    "Discriminator = tf.keras.Model(inputs=inputs, outputs=[outputs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(tf.keras.Model):\n",
    "    def __init__(self,latent_dim):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.generator = get_generator()\n",
    "        self.discriminator = get_discriminator()\n",
    "\n",
    "    def call(self,img,labels):\n",
    "        # encoder q(z|x,y)\n",
    "        enc1_output = self.encoder_block1(img)\n",
    "        # concat feature maps and one hot label vector\n",
    "        img_lbl_concat = np.concatenate((enc1_output,labels),axis=1)\n",
    "        z_mu,z_rho = self.encoder_block2(img_lbl_concat)\n",
    "\n",
    "        # sampling\n",
    "        epsilon = tf.random.normal(shape=z_mu.shape,mean=0.0,stddev=1.0)\n",
    "        z = z_mu + tf.math.softplus(z_rho) * epsilon\n",
    "\n",
    "        # decoder p(x|z,y)\n",
    "        z_lbl_concat = np.concatenate((z,labels),axis=1)\n",
    "        decoded_img = self.decoder_block(z_lbl_concat)\n",
    "\n",
    "        return z_mu,z_rho,decoded_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[-0.00242834],\n",
       "       [-0.00438537]], dtype=float32)>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VAE(latent_dim)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "\n",
    "kl_loss_tracker = tf.keras.metrics.Mean(name='kl_loss')\n",
    "mse_loss_tracker = tf.keras.metrics.Mean(name='mse_loss')\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    label_list = None\n",
    "    z_mu_list = None    \n",
    "\n",
    "    for _,(imgs,labels) in train_ds.enumerate():\n",
    "        \n",
    "        # training loop\n",
    "        with tf.GradientTape() as tape:\n",
    "            # forward pass\n",
    "            z_mu,z_rho,decoded_imgs = model(imgs)\n",
    "\n",
    "            # compute loss\n",
    "            mse,kl = elbo(z_mu,z_rho,decoded_imgs,imgs)\n",
    "            loss = mse + beta * kl\n",
    "        \n",
    "        # compute gradients\n",
    "        gradients = tape.gradient(loss,model.variables)\n",
    "\n",
    "        # update weights\n",
    "        optimizer.apply_gradients(zip(gradients, model.variables))\n",
    "\n",
    "        # update metrics\n",
    "        kl_loss_tracker.update_state(beta * kl)\n",
    "        mse_loss_tracker.update_state(mse)\n",
    "\n",
    "        # save encoded means and labels for latent space visualization\n",
    "        if label_list is None:\n",
    "            label_list = labels\n",
    "        else:\n",
    "            label_list = np.concatenate((label_list,labels))\n",
    "            \n",
    "        if z_mu_list is None:\n",
    "            z_mu_list = z_mu\n",
    "        else:\n",
    "            z_mu_list = np.concatenate((z_mu_list,z_mu),axis=0)\n",
    "\n",
    "\n",
    "    # generate new samples\n",
    "    generate_images(model,dataset_mean,dataset_std,temp_x_test=None)\n",
    "    # encode and decode samples from test data\n",
    "    generate_images(model,dataset_mean,dataset_std,temp_x_test=x_test[:16])\n",
    "    # visualize the latent space by non-linear dim reduction\n",
    "    visualize_latent_space(z_mu_list,label_list)\n",
    "    # plot 2D digit manifold if latent dim=2\n",
    "    if latent_dim==2:\n",
    "        plot_latent_images(model,dataset_mean,dataset_std)\n",
    "\n",
    "    # display metrics at the end of each epoch.\n",
    "    epoch_kl,epoch_mse = kl_loss_tracker.result(),mse_loss_tracker.result()\n",
    "    print(f'epoch: {epoch}, mse: {epoch_mse:.4f}, kl_div: {epoch_kl:.4f}')\n",
    "\n",
    "    # reset metric states\n",
    "    kl_loss_tracker.reset_state()\n",
    "    mse_loss_tracker.reset_state()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17915d4eccf26051373144ab496c4cfde1d85bab0b3b06c6ac905c8927260055"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('ml4hc_project2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
