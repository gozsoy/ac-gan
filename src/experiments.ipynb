{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roadmap:\n",
    "# 1-implement dcgan in tf and observe generated examples\n",
    "# 2-investigate tf dcgan implementation\n",
    "\n",
    "# 3-implement dcgan in torch and observed generated examples\n",
    "# 4-investigate torch dcgan implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 23:32:33.714503: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# [0,255] -> [0,1] -> [-1,1]\n",
    "x_train = (x_train/255.) * 2. - 1.\n",
    "\n",
    "x_train = np.expand_dims(x_train,axis=3)\n",
    "x_train = tf.cast(x_train,dtype=tf.float32)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_ds = train_ds.shuffle(1000).batch(64)\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATOR\n",
    "gen_inputs = tf.keras.Input(shape=(100,))\n",
    "x = tf.keras.layers.Dense(units=(7 * 7 * 128),activation='relu')(gen_inputs)\n",
    "x = tf.keras.layers.Reshape(target_shape=(7,7,128))(x)\n",
    "x = tf.keras.layers.Conv2DTranspose(filters=128,kernel_size=5,strides=1,activation='relu',padding='same')(x)\n",
    "x = tf.keras.layers.Conv2DTranspose(filters=64,kernel_size=5,strides=2,activation='relu',padding='same')(x)\n",
    "outputs = tf.keras.layers.Conv2DTranspose(filters=1,kernel_size=5,strides=2,activation='tanh',padding='same')(x)\n",
    "Generator = tf.keras.Model(inputs=gen_inputs, outputs=[outputs])\n",
    "\n",
    "# DISCRIMINATOR\n",
    "disc_inputs = tf.keras.Input(shape=(28,28,1))\n",
    "y = tf.keras.layers.Conv2D(filters=64,kernel_size=5,strides=2,padding='same')(disc_inputs)\n",
    "y = tf.keras.layers.LeakyReLU(alpha=0.2)(y)\n",
    "y = tf.keras.layers.Conv2D(filters=128,kernel_size=5,strides=2,padding='same')(y)\n",
    "y = tf.keras.layers.LeakyReLU(alpha=0.2)(y)\n",
    "y = tf.keras.layers.Flatten()(y)\n",
    "outputs = tf.keras.layers.Dense(units=1)(y)\n",
    "Discriminator = tf.keras.Model(inputs=disc_inputs, outputs=[outputs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/gokberk/Desktop/self-projects/simple-gan/src/experiments.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gokberk/Desktop/self-projects/simple-gan/src/experiments.ipynb#ch0000016?line=40'>41</a>\u001b[0m     disc_loss \u001b[39m=\u001b[39m loss_fn(y_true\u001b[39m=\u001b[39my_true,y_pred\u001b[39m=\u001b[39my_pred)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gokberk/Desktop/self-projects/simple-gan/src/experiments.ipynb#ch0000016?line=42'>43</a>\u001b[0m \u001b[39m# compute disc gradients\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gokberk/Desktop/self-projects/simple-gan/src/experiments.ipynb#ch0000016?line=43'>44</a>\u001b[0m disc_gradients \u001b[39m=\u001b[39m disc_tape\u001b[39m.\u001b[39mgradient(disc_loss,Discriminator\u001b[39m.\u001b[39mvariables)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gokberk/Desktop/self-projects/simple-gan/src/experiments.ipynb#ch0000016?line=45'>46</a>\u001b[0m \u001b[39m# update disc weights\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gokberk/Desktop/self-projects/simple-gan/src/experiments.ipynb#ch0000016?line=46'>47</a>\u001b[0m disc_optimizer\u001b[39m.\u001b[39mapply_gradients(\u001b[39mzip\u001b[39m(disc_gradients, Discriminator\u001b[39m.\u001b[39mvariables))\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py:1081\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py?line=1076'>1077</a>\u001b[0m \u001b[39mif\u001b[39;00m output_gradients \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py?line=1077'>1078</a>\u001b[0m   output_gradients \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ops\u001b[39m.\u001b[39mconvert_to_tensor(x)\n\u001b[1;32m   <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py?line=1078'>1079</a>\u001b[0m                       \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m nest\u001b[39m.\u001b[39mflatten(output_gradients)]\n\u001b[0;32m-> <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py?line=1080'>1081</a>\u001b[0m flat_grad \u001b[39m=\u001b[39m imperative_grad\u001b[39m.\u001b[39;49mimperative_grad(\n\u001b[1;32m   <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py?line=1081'>1082</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tape,\n\u001b[1;32m   <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py?line=1082'>1083</a>\u001b[0m     flat_targets,\n\u001b[1;32m   <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py?line=1083'>1084</a>\u001b[0m     flat_sources,\n\u001b[1;32m   <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py?line=1084'>1085</a>\u001b[0m     output_gradients\u001b[39m=\u001b[39;49moutput_gradients,\n\u001b[1;32m   <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py?line=1085'>1086</a>\u001b[0m     sources_raw\u001b[39m=\u001b[39;49mflat_sources_raw,\n\u001b[1;32m   <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py?line=1086'>1087</a>\u001b[0m     unconnected_gradients\u001b[39m=\u001b[39;49munconnected_gradients)\n\u001b[1;32m   <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py?line=1088'>1089</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent:\n\u001b[1;32m   <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py?line=1089'>1090</a>\u001b[0m   \u001b[39m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py?line=1090'>1091</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_watched_variables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tape\u001b[39m.\u001b[39mwatched_variables()\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/imperative_grad.py?line=62'>63</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/imperative_grad.py?line=63'>64</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/imperative_grad.py?line=64'>65</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mUnknown value for unconnected_gradients: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m unconnected_gradients)\n\u001b[0;32m---> <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/imperative_grad.py?line=66'>67</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_TapeGradient(\n\u001b[1;32m     <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/imperative_grad.py?line=67'>68</a>\u001b[0m     tape\u001b[39m.\u001b[39;49m_tape,  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m     <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/imperative_grad.py?line=68'>69</a>\u001b[0m     target,\n\u001b[1;32m     <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/imperative_grad.py?line=69'>70</a>\u001b[0m     sources,\n\u001b[1;32m     <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/imperative_grad.py?line=70'>71</a>\u001b[0m     output_gradients,\n\u001b[1;32m     <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/imperative_grad.py?line=71'>72</a>\u001b[0m     sources_raw,\n\u001b[1;32m     <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/imperative_grad.py?line=72'>73</a>\u001b[0m     compat\u001b[39m.\u001b[39;49mas_str(unconnected_gradients\u001b[39m.\u001b[39;49mvalue))\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py:156\u001b[0m, in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py?line=153'>154</a>\u001b[0m     gradient_name_scope \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m forward_pass_name_scope \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py?line=154'>155</a>\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[0;32m--> <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py?line=155'>156</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39;49mout_grads)\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py?line=156'>157</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py?line=157'>158</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39mout_grads)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/ops/nn_grad.py:343\u001b[0m, in \u001b[0;36m_BiasAddGrad\u001b[0;34m(op, received_grad)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/ops/nn_grad.py?line=339'>340</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/ops/nn_grad.py?line=340'>341</a>\u001b[0m   data_format \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/ops/nn_grad.py?line=341'>342</a>\u001b[0m \u001b[39mreturn\u001b[39;00m (received_grad,\n\u001b[0;32m--> <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/ops/nn_grad.py?line=342'>343</a>\u001b[0m         gen_nn_ops\u001b[39m.\u001b[39;49mbias_add_grad(\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/ops/nn_grad.py?line=343'>344</a>\u001b[0m             out_backprop\u001b[39m=\u001b[39;49mreceived_grad, data_format\u001b[39m=\u001b[39;49mdata_format))\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/ops/gen_nn_ops.py:749\u001b[0m, in \u001b[0;36mbias_add_grad\u001b[0;34m(out_backprop, data_format, name)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/ops/gen_nn_ops.py?line=746'>747</a>\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/ops/gen_nn_ops.py?line=747'>748</a>\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/ops/gen_nn_ops.py?line=748'>749</a>\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/ops/gen_nn_ops.py?line=749'>750</a>\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mBiasAddGrad\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, out_backprop, \u001b[39m\"\u001b[39;49m\u001b[39mdata_format\u001b[39;49m\u001b[39m\"\u001b[39;49m, data_format)\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/ops/gen_nn_ops.py?line=750'>751</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/tensorflow/python/ops/gen_nn_ops.py?line=751'>752</a>\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# loss function\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True,label_smoothing=0.0)\n",
    "\n",
    "# optimizers\n",
    "gen_optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0002)\n",
    "disc_optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0002)\n",
    "\n",
    "# metrics\n",
    "disc_loss_tracker = tf.keras.metrics.Mean(name='disc_loss')\n",
    "gen_loss_tracker = tf.keras.metrics.Mean(name='gen_loss')\n",
    "\n",
    "# tensorboard\n",
    "experiment_name = 'deneme'\n",
    "log_dir = '../logs/'+experiment_name\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "latent_code_size = 100\n",
    "# fix latent code to track improvement\n",
    "latent_code4visualization = tf.random.normal(shape=(16,latent_code_size))\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for _,real_imgs in train_ds.enumerate():\n",
    "        \n",
    "        # PART 1: DISC TRAINING, fixed generator\n",
    "        latent_code = tf.random.normal(shape=(real_imgs.shape[0],latent_code_size))\n",
    "\n",
    "        with tf.GradientTape() as disc_tape:\n",
    "            # generate fake images\n",
    "            generated_imgs = Generator(latent_code)\n",
    "\n",
    "            # forward pass real and fake images\n",
    "            real_preds,fake_preds = Discriminator(real_imgs),Discriminator(generated_imgs)\n",
    "            y_pred = tf.concat([real_preds,fake_preds],axis=0)\n",
    "            y_true = tf.concat([tf.ones_like(real_preds),tf.zeros_like(fake_preds)],axis=0)\n",
    "            # adding random noise to labels\n",
    "            y_true += 0.05 * tf.random.uniform(tf.shape(y_true))\n",
    "            \n",
    "            # compute loss\n",
    "            disc_loss = loss_fn(y_true=y_true,y_pred=y_pred)\n",
    "\n",
    "        # compute disc gradients\n",
    "        disc_gradients = disc_tape.gradient(disc_loss,Discriminator.variables)\n",
    "\n",
    "        # update disc weights\n",
    "        disc_optimizer.apply_gradients(zip(disc_gradients, Discriminator.variables))\n",
    "\n",
    "        # update disc metrics\n",
    "        disc_loss_tracker.update_state(disc_loss)\n",
    "\n",
    "\n",
    "        # PART 2: GEN TRAINING, fixed discriminator\n",
    "        latent_code = tf.random.normal(shape=(real_imgs.shape[0],latent_code_size))\n",
    "\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            # generate fake images\n",
    "            generated_imgs = Generator(latent_code)\n",
    "\n",
    "            # forward pass only images\n",
    "            fake_preds = Discriminator(generated_imgs)\n",
    "\n",
    "            # compute loss\n",
    "            gen_loss = loss_fn(y_true=tf.ones_like(fake_preds),y_pred=fake_preds)\n",
    "\n",
    "        # compute gen gradients\n",
    "        gen_gradients = gen_tape.gradient(gen_loss,Generator.variables)\n",
    "\n",
    "        # update gen weights\n",
    "        gen_optimizer.apply_gradients(zip(gen_gradients, Generator.variables))\n",
    "\n",
    "        # update gen metrics\n",
    "        gen_loss_tracker.update_state(gen_loss)\n",
    "\n",
    "\n",
    "    # generate sample images per epoch\n",
    "    test_generated_imgs = Generator(latent_code4visualization)\n",
    "    test_generated_imgs = (test_generated_imgs+1.)/2.\n",
    "    \n",
    "    # display and record metrics at the end of each epoch.\n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.scalar('disc_loss', disc_loss_tracker.result(), step=epoch)\n",
    "        tf.summary.scalar('gen_loss', gen_loss_tracker.result(), step=epoch)\n",
    "        tf.summary.image(name='test_samples',data=test_generated_imgs,max_outputs=test_generated_imgs.shape[0],step=epoch)\n",
    "\n",
    "    disc_loss,gen_loss = disc_loss_tracker.result(),gen_loss_tracker.result()\n",
    "    print(f'epoch: {epoch}, disc_loss: {disc_loss:.4f}, gen_loss: {gen_loss:.4f}')\n",
    "\n",
    "    # reset metric states\n",
    "    disc_loss_tracker.reset_state()\n",
    "    gen_loss_tracker.reset_state()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17915d4eccf26051373144ab496c4cfde1d85bab0b3b06c6ac905c8927260055"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('ml4hc_project2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
