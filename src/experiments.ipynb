{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-19 16:23:12.227756: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# [0,255] -> [0,1] -> [-1,1]\n",
    "x_train = (x_train/255.) * 2. - 1.\n",
    "\n",
    "x_train = np.expand_dims(x_train,axis=3)\n",
    "x_train = tf.cast(x_train,dtype=tf.float32)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_ds = train_ds.shuffle(1000).batch(256)\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conditional_Generator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.main_linear1 = layers.Dense(7 * 7 * 128)\n",
    "        self.main_reshape = layers.Reshape((7, 7, 128))\n",
    "        self.main_conv2d_tr1 = layers.Conv2DTranspose(128, kernel_size=4,\n",
    "                                strides=2, padding=\"same\")\n",
    "        self.main_leaky1 = layers.LeakyReLU(alpha=0.2)\n",
    "        self.main_conv2d_tr2 = layers.Conv2DTranspose(128, kernel_size=4,\n",
    "                                strides=2, padding=\"same\")\n",
    "        self.main_leaky2 = layers.LeakyReLU(alpha=0.2)\n",
    "        self.main_conv2d_tr3 = layers.Conv2DTranspose(1, (7, 7), padding=\"same\", activation=\"tanh\")\n",
    "\n",
    "        self.label_emb = layers.Embedding(input_dim=10, output_dim=30)\n",
    "        self.label_linear1 = layers.Dense(units = 7*7)\n",
    "        self.label_reshape = layers.Reshape(target_shape=(7,7,-1))\n",
    "\n",
    "        self.concat_layer = layers.Concatenate(axis=-1)\n",
    "\n",
    "    def call(self, latent_code, label):\n",
    "        \n",
    "        # turn label into activation map\n",
    "        label_map = self.label_reshape(self.label_linear1(self.label_emb(label)))\n",
    "\n",
    "        # turn latent code into activation map\n",
    "        img_activation_maps = self.main_reshape(self.main_linear1(latent_code))\n",
    "\n",
    "        # concatenate all maps\n",
    "        concat_activation_maps = self.concat_layer([img_activation_maps, label_map])\n",
    "\n",
    "        # upsample to create image\n",
    "        gen_img = self.main_conv2d_tr1(concat_activation_maps)\n",
    "        gen_img = self.main_leaky1(gen_img)\n",
    "        gen_img = self.main_conv2d_tr2(gen_img)\n",
    "        gen_img = self.main_leaky2(gen_img)\n",
    "        gen_img = self.main_conv2d_tr3(gen_img)\n",
    "\n",
    "        return gen_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, disc_loss: 3.0000, gen_loss: 6.0000\n"
     ]
    }
   ],
   "source": [
    "print(f'epoch: {2}, disc_loss: '\n",
    "    f'{3:.4f}, gen_loss: {6:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conditional_Discriminator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.main_conv2d_1 = layers.Conv2D(64, (4, 4), strides=(2, 2), padding=\"same\")\n",
    "        self.main_leaky_1 = layers.LeakyReLU(alpha=0.2)\n",
    "        self.main_conv2d_2 = layers.Conv2D(128, (4, 4), strides=(2, 2), padding=\"same\")\n",
    "        self.main_leaky_2 = layers.LeakyReLU(alpha=0.2)\n",
    "        self.main_conv2d_3 = layers.Conv2D(128, (4, 4), strides=(2, 2), padding=\"same\")\n",
    "        self.main_leaky_3 = layers.LeakyReLU(alpha=0.2)\n",
    "        self.main_maxpool = layers.GlobalMaxPooling2D()\n",
    "        self.main_linear = layers.Dense(1)\n",
    "\n",
    "        self.label_emb = layers.Embedding(input_dim=10, output_dim=50)\n",
    "        self.label_linear1 = layers.Dense(units = 28*28)\n",
    "        self.label_reshape = layers.Reshape(target_shape=(28,28,-1))\n",
    "\n",
    "        self.concat_layer = layers.Concatenate(axis=-1)\n",
    "\n",
    "    def call(self, img, label):\n",
    "        \n",
    "        # turn label into activation map\n",
    "        label_map = self.label_reshape(self.label_linear1(self.label_emb(label)))\n",
    "\n",
    "        # concatenate all maps\n",
    "        concat_img = self.concat_layer([img, label_map])\n",
    "\n",
    "        # upsample to create image\n",
    "        x = self.main_conv2d_1(concat_img)\n",
    "        x = self.main_leaky_1(x)\n",
    "        x = self.main_conv2d_2(x)\n",
    "        x = self.main_leaky_2(x)\n",
    "        x = self.main_conv2d_3(x)\n",
    "        x = self.main_leaky_3(x)\n",
    "        x = self.main_maxpool(x)\n",
    "        pred = self.main_linear(x)\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 2, 3,\n",
       "       4, 5, 6])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 1), dtype=float32, numpy=\n",
       "array([[-0.19739182],\n",
       "       [-0.24189803],\n",
       "       [-0.19816041],\n",
       "       [-0.20420948],\n",
       "       [-0.20160657],\n",
       "       [-0.17229977],\n",
       "       [-0.22877547],\n",
       "       [-0.2351267 ],\n",
       "       [-0.19057983],\n",
       "       [-0.1843774 ],\n",
       "       [-0.21497685],\n",
       "       [-0.18236613],\n",
       "       [-0.20547935],\n",
       "       [-0.22799948],\n",
       "       [-0.23009518],\n",
       "       [-0.24682301],\n",
       "       [-0.18350708],\n",
       "       [-0.21895677],\n",
       "       [-0.20812657],\n",
       "       [-0.17855173],\n",
       "       [-0.18525246],\n",
       "       [-0.21598698],\n",
       "       [-0.2046971 ],\n",
       "       [-0.11593517],\n",
       "       [-0.16629311],\n",
       "       [-0.24558498],\n",
       "       [-0.22924101],\n",
       "       [-0.24169654],\n",
       "       [-0.17694716],\n",
       "       [-0.19483742],\n",
       "       [-0.18677871],\n",
       "       [-0.18714418],\n",
       "       [-0.1756235 ],\n",
       "       [-0.22283612],\n",
       "       [-0.20114493],\n",
       "       [-0.25978965],\n",
       "       [-0.19561923],\n",
       "       [-0.16660868],\n",
       "       [-0.18597284],\n",
       "       [-0.20292082],\n",
       "       [-0.1996056 ],\n",
       "       [-0.139725  ],\n",
       "       [-0.24012002],\n",
       "       [-0.20743082],\n",
       "       [-0.14825688],\n",
       "       [-0.17691106],\n",
       "       [-0.21269199],\n",
       "       [-0.17311464],\n",
       "       [-0.16137904],\n",
       "       [-0.18560225],\n",
       "       [-0.17248139],\n",
       "       [-0.17088655],\n",
       "       [-0.25409943],\n",
       "       [-0.20809749],\n",
       "       [-0.22667201],\n",
       "       [-0.20562747],\n",
       "       [-0.18507329],\n",
       "       [-0.24182826],\n",
       "       [-0.18259451],\n",
       "       [-0.1815773 ],\n",
       "       [-0.15890107],\n",
       "       [-0.19554032],\n",
       "       [-0.21204676],\n",
       "       [-0.16930032],\n",
       "       [-0.19542523],\n",
       "       [-0.202952  ],\n",
       "       [-0.19862455],\n",
       "       [-0.20070484],\n",
       "       [-0.19669898],\n",
       "       [-0.25375187],\n",
       "       [-0.23180592],\n",
       "       [-0.17796731],\n",
       "       [-0.17619301],\n",
       "       [-0.17847282],\n",
       "       [-0.24572521],\n",
       "       [-0.18364358],\n",
       "       [-0.23685247],\n",
       "       [-0.21724954],\n",
       "       [-0.14910042],\n",
       "       [-0.17440273],\n",
       "       [-0.1833467 ],\n",
       "       [-0.21059945],\n",
       "       [-0.15341371],\n",
       "       [-0.1903442 ],\n",
       "       [-0.24446757],\n",
       "       [-0.17055048],\n",
       "       [-0.19429702],\n",
       "       [-0.17987992],\n",
       "       [-0.1844527 ],\n",
       "       [-0.20886831],\n",
       "       [-0.2435899 ],\n",
       "       [-0.22575891],\n",
       "       [-0.16950174],\n",
       "       [-0.19267662],\n",
       "       [-0.20440957],\n",
       "       [-0.18464842],\n",
       "       [-0.22027679],\n",
       "       [-0.21287376],\n",
       "       [-0.2420269 ],\n",
       "       [-0.18422046],\n",
       "       [-0.17063656],\n",
       "       [-0.18510284],\n",
       "       [-0.18455155],\n",
       "       [-0.20201379],\n",
       "       [-0.21678996],\n",
       "       [-0.16579062],\n",
       "       [-0.18345392],\n",
       "       [-0.21044508],\n",
       "       [-0.23956421],\n",
       "       [-0.2091125 ],\n",
       "       [-0.20626402],\n",
       "       [-0.17551643],\n",
       "       [-0.16169313],\n",
       "       [-0.15760604],\n",
       "       [-0.21447222],\n",
       "       [-0.19718939],\n",
       "       [-0.2126222 ],\n",
       "       [-0.23583013],\n",
       "       [-0.17891967],\n",
       "       [-0.12858528],\n",
       "       [-0.21233454],\n",
       "       [-0.1237718 ],\n",
       "       [-0.2390225 ],\n",
       "       [-0.20502132],\n",
       "       [-0.18594643],\n",
       "       [-0.20373341],\n",
       "       [-0.2030766 ],\n",
       "       [-0.18061405],\n",
       "       [-0.19388853],\n",
       "       [-0.191596  ],\n",
       "       [-0.20351931],\n",
       "       [-0.17269138],\n",
       "       [-0.17804149],\n",
       "       [-0.19315648],\n",
       "       [-0.21152115],\n",
       "       [-0.20855907],\n",
       "       [-0.1809721 ],\n",
       "       [-0.15941764],\n",
       "       [-0.21332398],\n",
       "       [-0.26234698],\n",
       "       [-0.22233139],\n",
       "       [-0.19059762],\n",
       "       [-0.20123924],\n",
       "       [-0.20249623],\n",
       "       [-0.18748079],\n",
       "       [-0.22644413],\n",
       "       [-0.18845798],\n",
       "       [-0.23641115],\n",
       "       [-0.24805269],\n",
       "       [-0.1282802 ],\n",
       "       [-0.2650624 ],\n",
       "       [-0.19314197],\n",
       "       [-0.22816403],\n",
       "       [-0.17049405],\n",
       "       [-0.16369748],\n",
       "       [-0.24061364],\n",
       "       [-0.16854951],\n",
       "       [-0.1858732 ],\n",
       "       [-0.19222113],\n",
       "       [-0.22650458],\n",
       "       [-0.20485383],\n",
       "       [-0.217407  ],\n",
       "       [-0.20506333],\n",
       "       [-0.17955364],\n",
       "       [-0.19121374],\n",
       "       [-0.23029669],\n",
       "       [-0.19475418],\n",
       "       [-0.19255728],\n",
       "       [-0.20888537],\n",
       "       [-0.19795287],\n",
       "       [-0.2037575 ],\n",
       "       [-0.16682574],\n",
       "       [-0.259228  ],\n",
       "       [-0.2135669 ],\n",
       "       [-0.20397034],\n",
       "       [-0.18766959],\n",
       "       [-0.1709436 ],\n",
       "       [-0.21545109],\n",
       "       [-0.17538866],\n",
       "       [-0.17644112],\n",
       "       [-0.14828163],\n",
       "       [-0.20452276],\n",
       "       [-0.21970703],\n",
       "       [-0.19136459],\n",
       "       [-0.2595665 ],\n",
       "       [-0.23627692],\n",
       "       [-0.19561616],\n",
       "       [-0.16936855],\n",
       "       [-0.15436485],\n",
       "       [-0.20570154],\n",
       "       [-0.20783186],\n",
       "       [-0.1904924 ],\n",
       "       [-0.18415892],\n",
       "       [-0.17230222],\n",
       "       [-0.2489976 ],\n",
       "       [-0.17847109],\n",
       "       [-0.24359472],\n",
       "       [-0.17712146],\n",
       "       [-0.2366811 ],\n",
       "       [-0.2051667 ],\n",
       "       [-0.18765754],\n",
       "       [-0.18197241],\n",
       "       [-0.23790073],\n",
       "       [-0.1736186 ],\n",
       "       [-0.17775519],\n",
       "       [-0.23610872],\n",
       "       [-0.14997709],\n",
       "       [-0.17320634],\n",
       "       [-0.17238036],\n",
       "       [-0.20939884],\n",
       "       [-0.19077295],\n",
       "       [-0.16057348],\n",
       "       [-0.22166371],\n",
       "       [-0.24905697],\n",
       "       [-0.2131226 ],\n",
       "       [-0.13180713],\n",
       "       [-0.26606226],\n",
       "       [-0.17655966],\n",
       "       [-0.1658984 ],\n",
       "       [-0.15601392],\n",
       "       [-0.2261592 ],\n",
       "       [-0.19151455],\n",
       "       [-0.2552584 ],\n",
       "       [-0.20391643],\n",
       "       [-0.2379961 ],\n",
       "       [-0.20162731],\n",
       "       [-0.19283555],\n",
       "       [-0.21046431],\n",
       "       [-0.19157715],\n",
       "       [-0.190653  ],\n",
       "       [-0.22626151],\n",
       "       [-0.24259844],\n",
       "       [-0.16450046],\n",
       "       [-0.20007282],\n",
       "       [-0.19878525],\n",
       "       [-0.23014951],\n",
       "       [-0.1927053 ],\n",
       "       [-0.22927372],\n",
       "       [-0.23788016],\n",
       "       [-0.27054816],\n",
       "       [-0.16646275],\n",
       "       [-0.20072813],\n",
       "       [-0.178632  ],\n",
       "       [-0.24681309],\n",
       "       [-0.16721515],\n",
       "       [-0.19957113],\n",
       "       [-0.18299168],\n",
       "       [-0.17618406],\n",
       "       [-0.18371776],\n",
       "       [-0.19522622],\n",
       "       [-0.14478204],\n",
       "       [-0.2172675 ],\n",
       "       [-0.19929166],\n",
       "       [-0.22224435],\n",
       "       [-0.17933813],\n",
       "       [-0.20658603]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for b in train_ds:\n",
    "    b\n",
    "    break\n",
    "\n",
    "gen = Conditional_Generator()\n",
    "disc = Conditional_Discriminator()\n",
    "latent_code = tf.random.normal(shape=(b[0].shape[0],128))\n",
    "disc(b[0],b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True,label_smoothing=0.1)\n",
    "\n",
    "# optimizers\n",
    "gen_optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0004)\n",
    "disc_optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0003)\n",
    "\n",
    "# metrics\n",
    "disc_loss_tracker = tf.keras.metrics.Mean(name='disc_loss')\n",
    "gen_loss_tracker = tf.keras.metrics.Mean(name='gen_loss')\n",
    "\n",
    "# tensorboard\n",
    "experiment_name = 'lbl01_glr0004_dlr0003_g13m_d390k'\n",
    "log_dir = '../logs/'+experiment_name\n",
    "img_save_dir = '../generated_imgs/'+experiment_name\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "latent_code_size = 128\n",
    "# fix latent code to track improvement\n",
    "latent_code4visualization = tf.random.normal(shape=(25,latent_code_size))\n",
    "epochs = 30\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for _,real_imgs in train_ds.enumerate():\n",
    "        \n",
    "        # PART 1: DISC TRAINING, fixed generator\n",
    "        latent_code = tf.random.normal(shape=(real_imgs.shape[0],latent_code_size))\n",
    "\n",
    "        with tf.GradientTape() as disc_tape:\n",
    "            # generate fake images\n",
    "            generated_imgs = Generator(latent_code)\n",
    "\n",
    "            # forward pass real and fake images\n",
    "            real_preds,fake_preds = Discriminator(real_imgs),Discriminator(generated_imgs)\n",
    "            y_pred = tf.concat([real_preds,fake_preds],axis=0)\n",
    "            y_true = tf.concat([tf.ones_like(real_preds),tf.zeros_like(fake_preds)],axis=0)\n",
    "            \n",
    "            # compute loss\n",
    "            disc_loss = loss_fn(y_true=y_true,y_pred=y_pred)\n",
    "\n",
    "        # compute disc gradients\n",
    "        disc_gradients = disc_tape.gradient(disc_loss,Discriminator.trainable_variables)\n",
    "\n",
    "        # update disc weights\n",
    "        disc_optimizer.apply_gradients(zip(disc_gradients, Discriminator.trainable_variables))\n",
    "\n",
    "        # update disc metrics\n",
    "        disc_loss_tracker.update_state(disc_loss)\n",
    "\n",
    "\n",
    "        # PART 2: GEN TRAINING, fixed discriminator\n",
    "        latent_code = tf.random.normal(shape=(real_imgs.shape[0],latent_code_size))\n",
    "\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            # generate fake images\n",
    "            generated_imgs = Generator(latent_code)\n",
    "\n",
    "            # forward pass only images\n",
    "            fake_preds = Discriminator(generated_imgs)\n",
    "\n",
    "            # compute loss\n",
    "            gen_loss = loss_fn(y_true=tf.ones_like(fake_preds),y_pred=fake_preds)\n",
    "\n",
    "        # compute gen gradients\n",
    "        gen_gradients = gen_tape.gradient(gen_loss,Generator.trainable_variables)\n",
    "\n",
    "        # update gen weights\n",
    "        gen_optimizer.apply_gradients(zip(gen_gradients, Generator.trainable_variables))\n",
    "\n",
    "        # update gen metrics\n",
    "        gen_loss_tracker.update_state(gen_loss)\n",
    "\n",
    "\n",
    "    # generate and save sample images per epoch\n",
    "    test_generated_imgs = Generator(latent_code4visualization)\n",
    "    test_generated_imgs = (((test_generated_imgs+1.)/2.) * 255.).numpy()\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    for i in range(test_generated_imgs.shape[0]):\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        plt.imshow(test_generated_imgs[i,:,:,0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.savefig(img_save_dir)\n",
    "    \n",
    "\n",
    "    # display and record metrics at the end of each epoch.\n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.scalar('disc_loss', disc_loss_tracker.result(), step=epoch)\n",
    "        tf.summary.scalar('gen_loss', gen_loss_tracker.result(), step=epoch)\n",
    "        tf.summary.image(name='test_samples',data=test_generated_imgs,max_outputs=test_generated_imgs.shape[0],step=epoch)\n",
    "\n",
    "    disc_loss,gen_loss = disc_loss_tracker.result(),gen_loss_tracker.result()\n",
    "    print(f'epoch: {epoch}, disc_loss: {disc_loss:.4f}, gen_loss: {gen_loss:.4f}')\n",
    "\n",
    "    # reset metric states\n",
    "    disc_loss_tracker.reset_state()\n",
    "    gen_loss_tracker.reset_state()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a73d1662bd3aab4de55a1a51be85519c6e25d5d617da76d142a49d5ef38ee143"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('torch_tf_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
